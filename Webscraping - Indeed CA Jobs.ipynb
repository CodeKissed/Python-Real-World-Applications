{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a basic webscraping script designed for personal use.\n",
    "\n",
    "This requires 3 user entries (keywords, phrase and location) to filter job search results.\n",
    "This will save all the job details from all the search results pages in a table format and save it locally as a csv file.\n",
    "\n",
    "Please note that there is no error handling in the user input phase as I built this for personal use (considering only job queries in BC, Canada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return an integer for values under Post Date for easy sorting later on\n",
    "def get_days_ago(date):\n",
    "    if date==\"Today\":\n",
    "        return 0\n",
    "    else:\n",
    "        return int(date[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracts job details from html tags and returns a dictionary\n",
    "def parse_job_details(item):\n",
    "    jobdetails={}\n",
    "    jobdetails[\"Job Title\"]=item.find(\"div\",{\"class\":\"title\"}).text.replace(\"\\n\",\"\")\n",
    "    jobdetails[\"Company\"]=item.find(\"span\",{\"class\":\"company\"}).text.replace(\"\\n\",\"\")\n",
    "    try:\n",
    "        jobdetails[\"Location\"]=item.find(\"span\",{\"class\":\"location accessible-contrast-color-location\"}).text\n",
    "        \n",
    "    except:\n",
    "        jobdetails[\"Location\"]=\"\"\n",
    "    try:\n",
    "        jobdetails[\"Salary\"]=item.find(\"span\",{\"class\":\"salaryText\"}).text.replace(\"\\n\",\"\")\n",
    "    except:\n",
    "        jobdetails[\"Salary\"]=\"\"\n",
    "    jobdetails[\"Summary\"]=item.find(\"div\",{\"class\":\"summary\"}).text.replace(\"\\n\",\"\")\n",
    "    jobdetails[\"Post Date\"]=get_days_ago(item.find(\"span\",{\"class\":\"date\"}).text.replace(\"\\n\",\"\"))\n",
    "    try:\n",
    "        jobdetails[\"Easy Apply\"]=item.find(\"span\",{\"class\":\"iaLabel\"}).text.replace(\"\\n\",\"\")\n",
    "    except:\n",
    "        jobdetails[\"Easy Apply\"]=\"\"\n",
    "    jobdetails[\"Page URL\"]=\"https://ca.indeed.com\"+item.find(\"a\").get('href')\n",
    "    return jobdetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Get user input\n",
    "keywords=input(\"Enter job title, keywords, or company : \")\n",
    "phrase=input(\"With the exact phrase : \")\n",
    "location=input(\"Enter city in BC, Canada: \")\n",
    "\n",
    "#Establish the url string based on user input\n",
    "base_url=\"https://ca.indeed.com/jobs?q=\"+keywords.replace(\" \",\"+\")+\"&as_phr=\"+phrase.replace(\" \",\"+\")+\"&l=\"+location.strip()+\"%2C+BC\"\n",
    "base_url2=\"&start=\"\n",
    "\n",
    "#Checking the first page of the search results\n",
    "loadpage= requests.get(base_url,headers={'User-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0'})\n",
    "pagecon = loadpage.content\n",
    "soup=BeautifulSoup(pagecon,\"html.parser\")\n",
    "\n",
    "#Find out how many pages are there in the search results\n",
    "page=soup.find_all(\"span\",{\"class\":\"pn\"})\n",
    "lastpage=len(page)\n",
    "\n",
    "#For each page in Indeed.com search results, the value after \"&start=\" is incremented by 10\n",
    "increment=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[] #main table where all job details are saved\n",
    "\n",
    "for page in range(0,lastpage):\n",
    "    url = base_url+base_url2+str(page*increment)\n",
    "\n",
    "    #Request info for each page in the search results\n",
    "    callpage=requests.get(url,headers={'User-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0'})\n",
    "    savepage=callpage.content\n",
    "    soup=BeautifulSoup(savepage,\"html.parser\")\n",
    "\n",
    "    #Defines the webscraping scope\n",
    "    all=soup.find_all(\"div\",{\"class\":\"jobsearch-SerpJobCard unifiedRow row result\"})   \n",
    "\n",
    "    #Process each item in soup                          \n",
    "    for item in all:\n",
    "        indeed = parse_job_details(item) #returns a dictionary \n",
    "        results.append(indeed) #job details are saved as a row in the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts the dictionary to a dataframe\n",
    "import pandas\n",
    "indeed_df=pandas.DataFrame(results)\n",
    "indeed_df.sort_values(by=['Post Date'], inplace=True,ascending=True)\n",
    "\n",
    "\n",
    "#Displays the dataframe (showing all job details in a table format)\n",
    "indeed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves the table locally in a csv format with the filename \"Indeed\"\n",
    "indeed_df.to_csv(\"Indeed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
